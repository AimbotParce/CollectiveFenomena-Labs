@article{markovChains,
   abstract = {'A fascinating and instructive guide to Markov chains for experienced users and newcomers alike This unique guide to Markov chains approaches the subject along the four convergent lines of mathematics, implementation, simulation, and experimentation. It introduces readers to the art of stochastic modeling, shows how to design computer implementations, and provides extensive worked examples with case studies. Markov Chains: From Theory to Implementation and Experimentation begins with a general introduction to the history of probability theory in which the author uses quantifiable examples to illustrate how probability theory arrived at the concept of discrete-time and the Markov model from experiments involving independent variables. An introduction to simple stochastic matrices and transition probabilities is followed by a simulation of a two-state Markov chain. The notion of steady state is explored in connection with the long-run distribution behavior of the Markov chain. Predictions based on Markov chains with more than two states are examined, followed by a discussion of the notion of absorbing Markov chains. Also covered in detail are topics relating to the average time spent in a state, various chain configurations, and n-state Markov chain simulations used for verifying experiments involving various diagram configurations. - Fascinating historical notes shed light on the key ideas that led to the development of the Markov model and its variants - Various configurations of Markov Chains and their limitations are explored at length - Numerous examples'from basic to complex'are presented in a comparative manner using a variety of color graphics - All algorithms presented can be analyzed in either Visual Basic, Java Script, or PHP - Designed to be useful to professional statisticians as well as readers without extensive knowledge of probability theory Covering both the theory underlying the Markov model and an array of Markov chain implementations, within a common conceptual framework, Markov Chains: From Theory to Implementation and Experimentation is a stimulating introduction to and a valuable reference for those wishing to deepen their understanding of this extremely valuable statistical tool. Paul A. Gagniuc, PhD, is Associate Professor at Polytechnic University of Bucharest, Romania. He obtained his MS and his PhD in genetics at the University of Bucharest. Dr. Gagniuc's work has been published in numerous high profile scientific journals, ranging from the Public Library of Science to BioMed Central and Nature journals. He is the recipient of several awards for exceptional scientific results and a highly active figure in the review process for different scientific areas. From observation to simulation -- Building the stochastic matrix -- Predictions by using 2-state Markov chains -- Predictions by using N-state Markov chains -- Absorbing Markov chains -- The average time spent in each state -- Discussions on different configurations of chains -- The simulation of an N-state Markov chain.},
   author = {Paul A. Gagniuc},
   isbn = {978-1-119-38755-8},
   title = {Markov chains : from theory to implementation and experimentation},
}
@article{markovStochastic,
   abstract = {2nd ed. Meyn and Tweedie is back! The bible on Markov chains in general state spaces has been brought up to date to reflect developments in the field since 1996 - many of them sparked by publication of the first edition. The pursuit of more efficient simulation algorithms for complex Markovian models, or algorithms for computation of optimal policies for controlled Markov models, has opened new directions for research on Markov chains. As a result, new applications have emerged across a wide range of topics including optimisation, statistics, and economics. New commentary and an epilogue by Sean Meyn summarise recent developments and references have been fully updated. This second edition reflects the same discipline and style that marked out the original and helped it to become a classic: proofs are rigorous and concise, the range of applications is broad and knowledgeable, and key ideas are accessible to practitioners with limited mathematical background. List of figures; Prologue to the second edition Peter W. Glynn; Preface to the second edition Sean Meyn; Preface to the first edition; Part I. Communication and Regeneration: 1. Heuristics; 2. Markov models; 3. Transition probabilities; 4. Irreducibility; 5. Pseudo-atoms; 6. Topology and continuity; 7. The nonlinear state space model; Part II. Stability Structures: 8. Transience and recurrence; 9. Harris and topological recurrence; 10. The existence of PI; 11. Drift and regularity; 12. Invariance and tightness; Part III. Convergence: 13. Ergodicity; 14. f-Ergodicity and f-regularity; 15. Geometric ergodicity; 16. V-Uniform ergodicity; 17. Sample paths and limit theorems; 18. Positivity; 19. Generalized classification criteria; 20. Epilogue to the second edition; Part IV. Appendices: A. Mud maps; B. Testing for stability; C. Glossary of model assumptions; D. Some mathematical background; Bibliography; Indexes.},
   author = {S. P. (Sean P.) Meyn and R. L. (Richard L.) Tweedie},
   isbn = {978-0-521-73182-9},
   pages = {594},
   publisher = {Cambridge University Press},
   title = {Markov chains and stochastic stability},
   year = {2009},
}
@web_page{markovWiki,
   title = {Markov chain - Wikipedia},
   url = {https://en.wikipedia.org/wiki/Markov_chain},
}
@article{montecarloMethods,
   author = {Gerard T. Barkema and Mark E. J. Newman},
   isbn = {9780198517979},
   journal = {Monte Carlo Methods in Statistical Physics},
   publisher = {Oxford University Press},
   title = {Monte Carlo simulations in surface science},
   year = {1999},
}
@report{apuntsClasse,
   author = {Antoni Planes},
   title = {Fenòmens Col·lectius i Transicions de Fase},
}
@web_page{stanfordIsingModel,
   author = {Stanford University},
   title = {The Ising Model},
   url = {https://stanford.edu/~jeffjar/statmech/intro4.html},
}
